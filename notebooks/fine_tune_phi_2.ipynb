{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMktZHoArmzVJZqa3O1wZK8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavankumarbalijepalli/pr-phi2-vs-defog/blob/main/notebooks/fine_tune_phi_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo-r_U3dxcel"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from datasets import load_from_disk\n",
        "from peft import LoraConfig\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from huggingface_hub import interpreter_login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter_login()\n",
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type='nf4',\n",
        "        bnb_4bit_compute_dtype='float16',\n",
        "        bnb_4bit_use_double_quant=False,\n",
        "    )\n",
        "device_map = {\"\": 0}"
      ],
      "metadata": {
        "id": "zNoMgCYIxngb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"microsoft/phi-2\",\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=device_map,\n",
        "        trust_remote_code=True,\n",
        "        use_auth_token=True\n",
        "    )\n",
        "\n",
        "model.config.pretraining_tp = 1\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=32,\n",
        "    target_modules=['lm_head.linear', 'transformer.embd.wte'], # is this correct?\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "YwiWba9sxw5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=500, #CHANGE THIS IF YOU WANT IT TO SAVE LESS OFTEN. I WOULDN'T SAVE MORE OFTEN BECAUSE OF SPACE\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=.3,\n",
        "    max_steps=10000,\n",
        "    warmup_ratio=.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        ")\n",
        "\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "W8zXhjLgx0sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"json\", data_files=\"your_dataset.json\", split=\"train\")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=2048,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=False,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "kqiVKvbzx5JD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}